# -*- coding: utf-8 -*-
"""Terminology_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SfZlQpfSSrGYlnvDvV6Q7M8lvra6STUD
"""

! python -m spacy download es_core_news_sm

import pandas as pd
import numpy as np
import jieba
import jieba.posseg as pseg
import spacy

"""# Load the Data"""

# Load the datasets
M2M_df = pd.read_csv('/content/translation_M2M100.csv')
finetuned_small_df = pd.read_csv('/content/finetune_small.csv')
finetuned_large_df = pd.read_csv('/content/finetune_large.csv')
Google_df = pd.read_csv('/content/translation_Google.csv')

"""# Select Random Segments"""

# Randomly select 100 segments
np.random.seed(42)
random_indices = np.random.choice(finetuned_df.index, size=100, replace=False)

selected_M2M = M2M_df.loc[random_indices]
selected_finetuned_small = finetuned_small_df.loc[random_indices]
selected_finetuned_large = finetuned_large_df.loc[random_indices]
selected_Google = Google_df.loc[random_indices]

"""# Extract Term Candidates"""

# Chinese NLP setup
extracted_terms_set = set()

# Function to extract unique nouns from Chinese text
def extract_unique_terms(text):
    words = pseg.cut(text)
    unique_terms = []
    for word, flag in words:
        if len(word) > 1 and flag in ['nr', 'ns', 'nt', 'nz'] and word not in extracted_terms_set:
            unique_terms.append(word)
            extracted_terms_set.add(word)
    return unique_terms

# Extract terms
selected_M2M['Extracted Chinese Terms'] = selected_M2M['Source Text'].apply(extract_unique_terms)

# Save to new CSV files
selected_M2M.to_csv('/content/M2M.csv', index=False)

extracted_terms_set.clear()

# Extract terms
selected_finetuned_small['Extracted Chinese Terms'] = selected_finetuned_small['Source Text'].apply(extract_unique_terms)

# Save to new CSV files
selected_finetuned_small.to_csv('/content/finetuned_small.csv', index=False)

extracted_terms_set.clear()

# Extract terms
selected_finetuned_large['Extracted Chinese Terms'] = selected_finetuned_large['Source Text'].apply(extract_unique_terms)

# Save to new CSV files
selected_finetuned_large.to_csv('/content/finetuned_large.csv', index=False)

extracted_terms_set.clear()

# Extract terms
selected_Google['Extracted Chinese Terms'] = selected_Google['Source Text'].apply(extract_unique_terms)

# Save to new CSV files
selected_Google.to_csv('/content/sampleGoogle.csv', index=False)

"""# Visualization"""

! pip install matplotlib
import matplotlib.pyplot as plt

# Data setup
models = ['M2M100_original', 'Finetuned_small', 'Finetuned_large', 'Google Translate']
terminology_verification = [0.54, 0.67, 0.75, 0.85]

fig, ax1 = plt.subplots()

# Bar chart for BLEU scores
color = 'tab:green'
ax1.set_ylabel('Terminology accuracy', color=color)
bars = ax1.bar(models, terminology_verification, color=[color if model != "Google Translate" else 'gray' for model in models])
ax1.tick_params(axis='y', labelcolor=color)
ax1.set_ylim(0, 1)

# Adding text labels to the bars
for bar in bars:
    yval = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), verticalalignment='bottom',  # verticalalignment can be adjusted as 'bottom' or 'center'
             ha='center', color=color)